{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß± LEGO Assembly Error Detection - Training Notebook\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tanamujaya/lego_assembly_detection/blob/main/LEGO_Assembly_Error_Detection_Training.ipynb)\n",
    "\n",
    "This notebook trains a YOLO-based computer vision model to detect assembly errors in LEGO models.\n",
    "\n",
    "**Features:**\n",
    "- YOLOv8 object detection (nano version optimized for Raspberry Pi)\n",
    "- Automatic train/val/test split (70/15/15)\n",
    "- Complete evaluation metrics and visualizations\n",
    "- Model export for Raspberry Pi deployment\n",
    "- Download all results in a single package\n",
    "\n",
    "**Author:** Tanaka Mujaya  \n",
    "**Project:** Bachelor's Thesis - HS Rhein-Waal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Setup Environment\n",
    "\n",
    "First, let's check if we're running on GPU and install the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install ultralytics --quiet\n",
    "!pip install kaggle --quiet\n",
    "!pip install scikit-learn --quiet\n",
    "\n",
    "print(\"‚úÖ Packages installed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import zipfile\n",
    "import random\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image as PILImage\n",
    "from IPython.display import Image, display\n",
    "\n",
    "from ultralytics import YOLO\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Download Dataset from Kaggle\n",
    "\n",
    "The dataset is hosted on Kaggle. You'll need to upload your Kaggle API credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload your kaggle.json file\n",
    "# Go to https://www.kaggle.com/settings -> API -> Create New Token\n",
    "# This downloads a kaggle.json file\n",
    "\n",
    "from google.colab import files\n",
    "\n",
    "print(\"Please upload your kaggle.json file:\")\n",
    "uploaded = files.upload()\n",
    "print(f\"Uploaded files: {list(uploaded.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Kaggle credentials\n",
    "!mkdir -p ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle/kaggle.json 2>/dev/null || cp Kaggle.json ~/.kaggle/kaggle.json 2>/dev/null\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "\n",
    "# Verify credentials\n",
    "!echo \"Checking credentials...\"\n",
    "!cat ~/.kaggle/kaggle.json\n",
    "print(\"\\n‚úÖ Kaggle credentials configured!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the dataset\n",
    "KAGGLE_DATASET = \"tanakamujaya/lad-dataset-5-0\"\n",
    "\n",
    "!kaggle datasets download -d {KAGGLE_DATASET} -p /content/data --unzip --force\n",
    "\n",
    "print(\"‚úÖ Dataset downloaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the dataset structure\n",
    "print(\"=== Dataset Structure ===\")\n",
    "!find /content/data -type d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Configuration\n",
    "\n",
    "Set up training parameters and paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CONFIGURATION - Modify these settings as needed\n",
    "# ============================================================================\n",
    "\n",
    "# Paths\n",
    "BASE_DIR = Path(\"/content\")\n",
    "DATA_DIR = BASE_DIR / \"data\"\n",
    "MODELS_DIR = BASE_DIR / \"models\"\n",
    "RESULTS_DIR = BASE_DIR / \"results\"\n",
    "YOLO_DATASET_DIR = BASE_DIR / \"yolo_dataset\"\n",
    "DOWNLOAD_DIR = BASE_DIR / \"download_package\"\n",
    "\n",
    "# Create directories\n",
    "MODELS_DIR.mkdir(exist_ok=True)\n",
    "RESULTS_DIR.mkdir(exist_ok=True)\n",
    "DOWNLOAD_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Dataset configuration\n",
    "DATASET_CONFIG = {\n",
    "    'train_split': 0.70,\n",
    "    'val_split': 0.15,\n",
    "    'test_split': 0.15,\n",
    "    'image_size': 416,  # Can use 320 for faster training, 640 for better accuracy\n",
    "    'random_seed': 42\n",
    "}\n",
    "\n",
    "# Model configuration\n",
    "MODEL_CONFIG = {\n",
    "    'variant': 'yolov8n',  # nano version (fastest, smallest)\n",
    "    'pretrained': True,\n",
    "    'num_classes': 2,  # correct_assembly, assembly_error\n",
    "}\n",
    "\n",
    "# Training configuration\n",
    "TRAINING_CONFIG = {\n",
    "    'epochs': 40,\n",
    "    'batch_size': 16,\n",
    "    'learning_rate': 0.001,\n",
    "    'patience': 20,  # Early stopping\n",
    "    'device': 0,  # GPU (use 'cpu' if no GPU)\n",
    "    'workers': 2,\n",
    "}\n",
    "\n",
    "# Class names\n",
    "CLASS_NAMES = ['correct_assembly', 'assembly_error']\n",
    "\n",
    "print(\"‚úÖ Configuration set!\")\n",
    "print(f\"   Model: {MODEL_CONFIG['variant']}\")\n",
    "print(f\"   Image size: {DATASET_CONFIG['image_size']}\")\n",
    "print(f\"   Epochs: {TRAINING_CONFIG['epochs']}\")\n",
    "print(f\"   Batch size: {TRAINING_CONFIG['batch_size']}\")\n",
    "print(f\"   Train/Val/Test split: {int(DATASET_CONFIG['train_split']*100)}/{int(DATASET_CONFIG['val_split']*100)}/{int(DATASET_CONFIG['test_split']*100)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Prepare Dataset\n",
    "\n",
    "Find the dataset, split into train/val/test, and create YOLO format structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_dataset(data_dir):\n",
    "    \"\"\"\n",
    "    Find the images and labels folders in the dataset.\n",
    "    Handles various folder structures and naming conventions.\n",
    "    \"\"\"\n",
    "    data_dir = Path(data_dir)\n",
    "    \n",
    "    print(\"üîç Searching for dataset...\")\n",
    "    \n",
    "    # Look for images folder (case-insensitive)\n",
    "    images_dir = None\n",
    "    labels_dir = None\n",
    "    \n",
    "    # Search for Images/images folder\n",
    "    for folder in data_dir.rglob('*'):\n",
    "        if folder.is_dir():\n",
    "            folder_name_lower = folder.name.lower()\n",
    "            if folder_name_lower == 'images':\n",
    "                images_dir = folder\n",
    "            elif folder_name_lower == 'labels':\n",
    "                labels_dir = folder\n",
    "    \n",
    "    if images_dir and labels_dir:\n",
    "        print(f\"   ‚úÖ Found dataset!\")\n",
    "        print(f\"   Images: {images_dir}\")\n",
    "        print(f\"   Labels: {labels_dir}\")\n",
    "        return images_dir, labels_dir\n",
    "    \n",
    "    raise FileNotFoundError(f\"Could not find Images/Labels folders in {data_dir}\")\n",
    "\n",
    "\n",
    "def get_image_label_pairs(images_dir, labels_dir):\n",
    "    \"\"\"\n",
    "    Get matching image and label file pairs.\n",
    "    \"\"\"\n",
    "    images_dir = Path(images_dir)\n",
    "    labels_dir = Path(labels_dir)\n",
    "    \n",
    "    image_extensions = {'.jpg', '.jpeg', '.png', '.bmp'}\n",
    "    pairs = []\n",
    "    \n",
    "    for img_path in images_dir.iterdir():\n",
    "        if img_path.suffix.lower() in image_extensions:\n",
    "            label_path = labels_dir / f\"{img_path.stem}.txt\"\n",
    "            if label_path.exists():\n",
    "                pairs.append((img_path, label_path))\n",
    "    \n",
    "    return pairs\n",
    "\n",
    "\n",
    "# Find the dataset\n",
    "images_dir, labels_dir = find_dataset(DATA_DIR)\n",
    "\n",
    "# Get all image-label pairs\n",
    "all_pairs = get_image_label_pairs(images_dir, labels_dir)\n",
    "print(f\"\\nüìä Found {len(all_pairs)} image-label pairs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_yolo_dataset(pairs, output_dir, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15, seed=42):\n",
    "    \"\"\"\n",
    "    Split dataset and create YOLO format directory structure.\n",
    "    \"\"\"\n",
    "    output_dir = Path(output_dir)\n",
    "    \n",
    "    # Remove old dataset if exists\n",
    "    if output_dir.exists():\n",
    "        shutil.rmtree(output_dir)\n",
    "    \n",
    "    # Create directory structure\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        (output_dir / split / 'images').mkdir(parents=True, exist_ok=True)\n",
    "        (output_dir / split / 'labels').mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Split dataset\n",
    "    random.seed(seed)\n",
    "    shuffled_pairs = pairs.copy()\n",
    "    random.shuffle(shuffled_pairs)\n",
    "    \n",
    "    n_total = len(shuffled_pairs)\n",
    "    n_train = int(n_total * train_ratio)\n",
    "    n_val = int(n_total * val_ratio)\n",
    "    \n",
    "    train_pairs = shuffled_pairs[:n_train]\n",
    "    val_pairs = shuffled_pairs[n_train:n_train + n_val]\n",
    "    test_pairs = shuffled_pairs[n_train + n_val:]\n",
    "    \n",
    "    splits = {\n",
    "        'train': train_pairs,\n",
    "        'val': val_pairs,\n",
    "        'test': test_pairs\n",
    "    }\n",
    "    \n",
    "    # Copy files to respective directories\n",
    "    for split_name, split_pairs in splits.items():\n",
    "        print(f\"   Processing {split_name}: {len(split_pairs)} samples\")\n",
    "        for img_path, label_path in split_pairs:\n",
    "            shutil.copy(img_path, output_dir / split_name / 'images' / img_path.name)\n",
    "            shutil.copy(label_path, output_dir / split_name / 'labels' / label_path.name)\n",
    "    \n",
    "    # Create dataset.yaml\n",
    "    yaml_content = f\"\"\"# LEGO Assembly Error Detection Dataset\n",
    "# Auto-generated by training notebook\n",
    "\n",
    "path: {output_dir}\n",
    "train: train/images\n",
    "val: val/images\n",
    "test: test/images\n",
    "\n",
    "# Classes\n",
    "names:\n",
    "  0: correct_assembly\n",
    "  1: assembly_error\n",
    "\n",
    "# Number of classes\n",
    "nc: 2\n",
    "\"\"\"\n",
    "    \n",
    "    yaml_path = output_dir / 'dataset.yaml'\n",
    "    with open(yaml_path, 'w') as f:\n",
    "        f.write(yaml_content)\n",
    "    \n",
    "    return yaml_path, splits\n",
    "\n",
    "\n",
    "# Create YOLO dataset structure\n",
    "print(\"üìÅ Creating YOLO dataset structure...\")\n",
    "\n",
    "yaml_path, splits = create_yolo_dataset(\n",
    "    all_pairs,\n",
    "    YOLO_DATASET_DIR,\n",
    "    train_ratio=DATASET_CONFIG['train_split'],\n",
    "    val_ratio=DATASET_CONFIG['val_split'],\n",
    "    test_ratio=DATASET_CONFIG['test_split'],\n",
    "    seed=DATASET_CONFIG['random_seed']\n",
    ")\n",
    "\n",
    "train_count = len(splits['train'])\n",
    "val_count = len(splits['val'])\n",
    "test_count = len(splits['test'])\n",
    "total_count = train_count + val_count + test_count\n",
    "\n",
    "print(f\"\\n‚úÖ Dataset prepared!\")\n",
    "print(f\"   Train: {train_count} images ({train_count/total_count*100:.1f}%)\")\n",
    "print(f\"   Val:   {val_count} images ({val_count/total_count*100:.1f}%)\")\n",
    "print(f\"   Test:  {test_count} images ({test_count/total_count*100:.1f}%)\")\n",
    "print(f\"   Total: {total_count} images\")\n",
    "print(f\"\\n   YAML config: {yaml_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview some training images\n",
    "train_images_dir = YOLO_DATASET_DIR / 'train' / 'images'\n",
    "all_images = list(train_images_dir.iterdir())\n",
    "sample_images = random.sample(all_images, min(4, len(all_images)))\n",
    "\n",
    "fig, axes = plt.subplots(1, len(sample_images), figsize=(16, 4))\n",
    "if len(sample_images) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for ax, img_path in zip(axes, sample_images):\n",
    "    img = PILImage.open(img_path)\n",
    "    ax.imshow(img)\n",
    "    ax.set_title(img_path.name[:20] + '...')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.suptitle('Sample Training Images', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Train the Model\n",
    "\n",
    "Now let's train the YOLOv8 model on our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "print(f\"üöÄ Loading {MODEL_CONFIG['variant']} model...\")\n",
    "\n",
    "model = YOLO(f\"{MODEL_CONFIG['variant']}.pt\")\n",
    "\n",
    "print(\"‚úÖ Model loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "print(\"üèãÔ∏è Starting training...\")\n",
    "print(f\"   This may take a while depending on your GPU.\")\n",
    "print(f\"   Epochs: {TRAINING_CONFIG['epochs']}\")\n",
    "print(f\"   Batch size: {TRAINING_CONFIG['batch_size']}\")\n",
    "print()\n",
    "\n",
    "# Training arguments\n",
    "train_args = {\n",
    "    'data': str(yaml_path),\n",
    "    'epochs': TRAINING_CONFIG['epochs'],\n",
    "    'batch': TRAINING_CONFIG['batch_size'],\n",
    "    'imgsz': DATASET_CONFIG['image_size'],\n",
    "    'device': TRAINING_CONFIG['device'],\n",
    "    'workers': TRAINING_CONFIG['workers'],\n",
    "    'patience': TRAINING_CONFIG['patience'],\n",
    "    'save': True,\n",
    "    'project': str(RESULTS_DIR),\n",
    "    'name': 'train',\n",
    "    'exist_ok': True,\n",
    "    'pretrained': MODEL_CONFIG['pretrained'],\n",
    "    'optimizer': 'Adam',\n",
    "    'lr0': TRAINING_CONFIG['learning_rate'],\n",
    "    'verbose': True,\n",
    "    'plots': True,\n",
    "    # Augmentation\n",
    "    'hsv_h': 0.015,\n",
    "    'hsv_s': 0.7,\n",
    "    'hsv_v': 0.4,\n",
    "    'degrees': 10,\n",
    "    'translate': 0.1,\n",
    "    'scale': 0.5,\n",
    "    'fliplr': 0.5,\n",
    "    'mosaic': 1.0,\n",
    "    'mixup': 0.1,\n",
    "}\n",
    "\n",
    "# Start training\n",
    "results = model.train(**train_args)\n",
    "\n",
    "print(\"\\n‚úÖ Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Evaluate Results\n",
    "\n",
    "Let's look at all the training metrics and evaluation results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define results directory\n",
    "train_results_dir = RESULTS_DIR / 'train'\n",
    "\n",
    "print(\"üìÅ Training outputs generated:\")\n",
    "print(\"=\" * 50)\n",
    "for item in sorted(train_results_dir.iterdir()):\n",
    "    if item.is_file():\n",
    "        size_kb = item.stat().st_size / 1024\n",
    "        print(f\"   {item.name:<40} ({size_kb:.1f} KB)\")\n",
    "    else:\n",
    "        print(f\"   {item.name}/ (folder)\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Training Results Summary (results.png)\n",
    "print(\"\\nüìà Training Results Summary\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "results_img = train_results_dir / 'results.png'\n",
    "if results_img.exists():\n",
    "    display(Image(filename=str(results_img), width=900))\n",
    "else:\n",
    "    print(\"results.png not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Confusion Matrix\n",
    "print(\"\\nüìä Confusion Matrix\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "confusion_matrix_img = train_results_dir / 'confusion_matrix.png'\n",
    "if confusion_matrix_img.exists():\n",
    "    display(Image(filename=str(confusion_matrix_img), width=600))\n",
    "else:\n",
    "    print(\"confusion_matrix.png not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Normalized Confusion Matrix\n",
    "print(\"\\nüìä Normalized Confusion Matrix\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "confusion_matrix_norm_img = train_results_dir / 'confusion_matrix_normalized.png'\n",
    "if confusion_matrix_norm_img.exists():\n",
    "    display(Image(filename=str(confusion_matrix_norm_img), width=600))\n",
    "else:\n",
    "    print(\"confusion_matrix_normalized.png not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display F1 Curve\n",
    "print(\"\\nüìà F1-Confidence Curve (BoxF1_curve)\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "f1_curve_img = train_results_dir / 'BoxF1_curve.png'\n",
    "if f1_curve_img.exists():\n",
    "    display(Image(filename=str(f1_curve_img), width=600))\n",
    "else:\n",
    "    print(\"BoxF1_curve.png not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Precision Curve\n",
    "print(\"\\nüìà Precision-Confidence Curve (BoxP_curve)\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "p_curve_img = train_results_dir / 'BoxP_curve.png'\n",
    "if p_curve_img.exists():\n",
    "    display(Image(filename=str(p_curve_img), width=600))\n",
    "else:\n",
    "    print(\"BoxP_curve.png not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Recall Curve\n",
    "print(\"\\nüìà Recall-Confidence Curve (BoxR_curve)\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "r_curve_img = train_results_dir / 'BoxR_curve.png'\n",
    "if r_curve_img.exists():\n",
    "    display(Image(filename=str(r_curve_img), width=600))\n",
    "else:\n",
    "    print(\"BoxR_curve.png not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display PR Curve\n",
    "print(\"\\nüìà Precision-Recall Curve (BoxPR_curve)\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "pr_curve_img = train_results_dir / 'BoxPR_curve.png'\n",
    "if pr_curve_img.exists():\n",
    "    display(Image(filename=str(pr_curve_img), width=600))\n",
    "else:\n",
    "    print(\"BoxPR_curve.png not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Labels Distribution\n",
    "print(\"\\nüìä Labels Distribution\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "labels_img = train_results_dir / 'labels.jpg'\n",
    "if labels_img.exists():\n",
    "    display(Image(filename=str(labels_img), width=800))\n",
    "else:\n",
    "    print(\"labels.jpg not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Training Batch Samples\n",
    "print(\"\\nüñºÔ∏è Training Batch Samples\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for i in range(3):\n",
    "    batch_img = train_results_dir / f'train_batch{i}.jpg'\n",
    "    if batch_img.exists():\n",
    "        print(f\"\\nTrain Batch {i}:\")\n",
    "        display(Image(filename=str(batch_img), width=800))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Validation Batch Predictions\n",
    "print(\"\\nüñºÔ∏è Validation Predictions vs Labels\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "for i in range(3):\n",
    "    val_labels_img = train_results_dir / f'val_batch{i}_labels.jpg'\n",
    "    val_pred_img = train_results_dir / f'val_batch{i}_pred.jpg'\n",
    "    \n",
    "    if val_labels_img.exists() and val_pred_img.exists():\n",
    "        print(f\"\\nValidation Batch {i} - Labels:\")\n",
    "        display(Image(filename=str(val_labels_img), width=800))\n",
    "        print(f\"Validation Batch {i} - Predictions:\")\n",
    "        display(Image(filename=str(val_pred_img), width=800))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Training Results CSV (per epoch metrics)\n",
    "print(\"\\nüìã Training Metrics Per Epoch (results.csv)\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "results_csv = train_results_dir / 'results.csv'\n",
    "if results_csv.exists():\n",
    "    df = pd.read_csv(results_csv)\n",
    "    # Clean up column names (remove leading spaces)\n",
    "    df.columns = df.columns.str.strip()\n",
    "    \n",
    "    print(f\"\\nTotal epochs: {len(df)}\")\n",
    "    print(f\"\\nColumns available:\")\n",
    "    for col in df.columns:\n",
    "        print(f\"   - {col}\")\n",
    "    \n",
    "    print(\"\\nüìä Full Training History:\")\n",
    "    display(df)\n",
    "else:\n",
    "    print(\"results.csv not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Training Arguments\n",
    "print(\"\\n‚öôÔ∏è Training Arguments (args.yaml)\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "args_yaml = train_results_dir / 'args.yaml'\n",
    "if args_yaml.exists():\n",
    "    with open(args_yaml, 'r') as f:\n",
    "        print(f.read())\n",
    "else:\n",
    "    print(\"args.yaml not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "print(\"\\nüìä Evaluating on Test Set...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Load best model\n",
    "best_model_path = train_results_dir / 'weights' / 'best.pt'\n",
    "best_model = YOLO(str(best_model_path))\n",
    "\n",
    "# Run evaluation on test set\n",
    "test_results = best_model.val(\n",
    "    data=str(yaml_path),\n",
    "    split='test',\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"üìà TEST SET RESULTS\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Precision:    {test_results.results_dict['metrics/precision(B)']:.4f}\")\n",
    "print(f\"Recall:       {test_results.results_dict['metrics/recall(B)']:.4f}\")\n",
    "print(f\"mAP@0.5:      {test_results.results_dict['metrics/mAP50(B)']:.4f}\")\n",
    "print(f\"mAP@0.5:0.95: {test_results.results_dict['metrics/mAP50-95(B)']:.4f}\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Test Inference\n",
    "\n",
    "Let's run inference on some test images to see the model in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference on random test images\n",
    "test_images_dir = YOLO_DATASET_DIR / 'test' / 'images'\n",
    "test_images = list(test_images_dir.iterdir())\n",
    "sample_test_images = random.sample(test_images, min(4, len(test_images)))\n",
    "\n",
    "print(\"üîç Running inference on sample test images...\\n\")\n",
    "\n",
    "# Run prediction\n",
    "predictions = best_model.predict(\n",
    "    source=sample_test_images,\n",
    "    save=True,\n",
    "    project=str(RESULTS_DIR),\n",
    "    name='test_predictions',\n",
    "    exist_ok=True,\n",
    "    conf=0.5\n",
    ")\n",
    "\n",
    "# Display predictions\n",
    "pred_dir = RESULTS_DIR / 'test_predictions'\n",
    "pred_images = [f for f in pred_dir.iterdir() if f.suffix.lower() in {'.jpg', '.jpeg', '.png'}]\n",
    "\n",
    "if pred_images:\n",
    "    fig, axes = plt.subplots(1, len(pred_images), figsize=(16, 4))\n",
    "    if len(pred_images) == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for ax, img_path in zip(axes, pred_images):\n",
    "        img = PILImage.open(img_path)\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(img_path.name[:25])\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.suptitle('Model Predictions on Test Images', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No prediction images found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Export and Download Everything\n",
    "\n",
    "Save the trained model and download all results in a comprehensive package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy best model to models directory\n",
    "final_model_path = MODELS_DIR / 'lego_detector_best.pt'\n",
    "shutil.copy(best_model_path, final_model_path)\n",
    "\n",
    "# Also copy last model\n",
    "last_model_path = train_results_dir / 'weights' / 'last.pt'\n",
    "if last_model_path.exists():\n",
    "    shutil.copy(last_model_path, MODELS_DIR / 'lego_detector_last.pt')\n",
    "\n",
    "print(f\"‚úÖ Best model saved to: {final_model_path}\")\n",
    "print(f\"   Model size: {final_model_path.stat().st_size / 1024 / 1024:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to ONNX format (for optimized inference on Raspberry Pi)\n",
    "print(\"üì¶ Exporting to ONNX format...\")\n",
    "\n",
    "onnx_path = best_model.export(\n",
    "    format='onnx',\n",
    "    imgsz=DATASET_CONFIG['image_size'],\n",
    "    simplify=True\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ ONNX model saved to: {onnx_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive download package with ALL results\n",
    "print(\"üì¶ Creating comprehensive download package...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Clear and recreate download directory\n",
    "if DOWNLOAD_DIR.exists():\n",
    "    shutil.rmtree(DOWNLOAD_DIR)\n",
    "DOWNLOAD_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Create subdirectories\n",
    "(DOWNLOAD_DIR / 'models').mkdir(exist_ok=True)\n",
    "(DOWNLOAD_DIR / 'metrics').mkdir(exist_ok=True)\n",
    "(DOWNLOAD_DIR / 'curves').mkdir(exist_ok=True)\n",
    "(DOWNLOAD_DIR / 'visualizations').mkdir(exist_ok=True)\n",
    "(DOWNLOAD_DIR / 'batch_samples').mkdir(exist_ok=True)\n",
    "\n",
    "# Copy models\n",
    "print(\"\\nüìÅ Copying models...\")\n",
    "shutil.copy(final_model_path, DOWNLOAD_DIR / 'models' / 'best.pt')\n",
    "if (MODELS_DIR / 'lego_detector_last.pt').exists():\n",
    "    shutil.copy(MODELS_DIR / 'lego_detector_last.pt', DOWNLOAD_DIR / 'models' / 'last.pt')\n",
    "if Path(onnx_path).exists():\n",
    "    shutil.copy(onnx_path, DOWNLOAD_DIR / 'models' / Path(onnx_path).name)\n",
    "print(\"   ‚úÖ Models copied\")\n",
    "\n",
    "# Copy metrics files (CSV and YAML)\n",
    "print(\"\\nüìÅ Copying metrics files...\")\n",
    "metrics_files = ['results.csv', 'args.yaml']\n",
    "for f in metrics_files:\n",
    "    src = train_results_dir / f\n",
    "    if src.exists():\n",
    "        shutil.copy(src, DOWNLOAD_DIR / 'metrics' / f)\n",
    "        print(f\"   ‚úÖ {f}\")\n",
    "\n",
    "# Copy curve images\n",
    "print(\"\\nüìÅ Copying curve plots...\")\n",
    "curve_files = [\n",
    "    'BoxF1_curve.png',\n",
    "    'BoxP_curve.png', \n",
    "    'BoxR_curve.png',\n",
    "    'BoxPR_curve.png',\n",
    "    'results.png'\n",
    "]\n",
    "for f in curve_files:\n",
    "    src = train_results_dir / f\n",
    "    if src.exists():\n",
    "        shutil.copy(src, DOWNLOAD_DIR / 'curves' / f)\n",
    "        print(f\"   ‚úÖ {f}\")\n",
    "\n",
    "# Copy visualization images\n",
    "print(\"\\nüìÅ Copying visualizations...\")\n",
    "viz_files = [\n",
    "    'confusion_matrix.png',\n",
    "    'confusion_matrix_normalized.png',\n",
    "    'labels.jpg',\n",
    "    'labels_correlogram.jpg'\n",
    "]\n",
    "for f in viz_files:\n",
    "    src = train_results_dir / f\n",
    "    if src.exists():\n",
    "        shutil.copy(src, DOWNLOAD_DIR / 'visualizations' / f)\n",
    "        print(f\"   ‚úÖ {f}\")\n",
    "\n",
    "# Copy batch samples\n",
    "print(\"\\nüìÅ Copying batch samples...\")\n",
    "for f in train_results_dir.iterdir():\n",
    "    if 'batch' in f.name and f.suffix in ['.jpg', '.png']:\n",
    "        shutil.copy(f, DOWNLOAD_DIR / 'batch_samples' / f.name)\n",
    "        print(f\"   ‚úÖ {f.name}\")\n",
    "\n",
    "# Create a summary text file\n",
    "print(\"\\nüìÅ Creating summary file...\")\n",
    "summary_content = f\"\"\"LEGO Assembly Error Detection - Training Results Summary\n",
    "{'=' * 60}\n",
    "Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\n",
    "DATASET\n",
    "{'-' * 40}\n",
    "Total images: {total_count}\n",
    "Train: {train_count} ({train_count/total_count*100:.1f}%)\n",
    "Val: {val_count} ({val_count/total_count*100:.1f}%)\n",
    "Test: {test_count} ({test_count/total_count*100:.1f}%)\n",
    "\n",
    "MODEL\n",
    "{'-' * 40}\n",
    "Architecture: {MODEL_CONFIG['variant']}\n",
    "Image size: {DATASET_CONFIG['image_size']}\n",
    "Classes: {CLASS_NAMES}\n",
    "\n",
    "TRAINING CONFIG\n",
    "{'-' * 40}\n",
    "Epochs: {TRAINING_CONFIG['epochs']}\n",
    "Batch size: {TRAINING_CONFIG['batch_size']}\n",
    "Learning rate: {TRAINING_CONFIG['learning_rate']}\n",
    "Optimizer: Adam\n",
    "Early stopping patience: {TRAINING_CONFIG['patience']}\n",
    "\n",
    "TEST SET RESULTS\n",
    "{'-' * 40}\n",
    "Precision: {test_results.results_dict['metrics/precision(B)']:.4f}\n",
    "Recall: {test_results.results_dict['metrics/recall(B)']:.4f}\n",
    "mAP@0.5: {test_results.results_dict['metrics/mAP50(B)']:.4f}\n",
    "mAP@0.5:0.95: {test_results.results_dict['metrics/mAP50-95(B)']:.4f}\n",
    "\n",
    "PACKAGE CONTENTS\n",
    "{'-' * 40}\n",
    "models/\n",
    "  - best.pt (Best model weights)\n",
    "  - last.pt (Last epoch weights)\n",
    "  - *.onnx (ONNX export for deployment)\n",
    "\n",
    "metrics/\n",
    "  - results.csv (Per-epoch training metrics)\n",
    "  - args.yaml (Training configuration)\n",
    "\n",
    "curves/\n",
    "  - results.png (Training curves summary)\n",
    "  - BoxF1_curve.png (F1-Confidence curve)\n",
    "  - BoxP_curve.png (Precision-Confidence curve)\n",
    "  - BoxR_curve.png (Recall-Confidence curve)\n",
    "  - BoxPR_curve.png (Precision-Recall curve)\n",
    "\n",
    "visualizations/\n",
    "  - confusion_matrix.png\n",
    "  - confusion_matrix_normalized.png\n",
    "  - labels.jpg (Label distribution)\n",
    "\n",
    "batch_samples/\n",
    "  - train_batch*.jpg (Training batch visualizations)\n",
    "  - val_batch*_labels.jpg (Validation ground truth)\n",
    "  - val_batch*_pred.jpg (Validation predictions)\n",
    "\n",
    "{'=' * 60}\n",
    "GitHub: https://github.com/tanamujaya/lego_assembly_detection\n",
    "Dataset: https://www.kaggle.com/datasets/tanakamujaya/lad-dataset-5-0\n",
    "\"\"\"\n",
    "\n",
    "with open(DOWNLOAD_DIR / 'SUMMARY.txt', 'w') as f:\n",
    "    f.write(summary_content)\n",
    "print(\"   ‚úÖ SUMMARY.txt\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"‚úÖ Download package created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create zip file for download\n",
    "print(\"üì¶ Creating zip archive...\")\n",
    "\n",
    "zip_filename = f\"lego_detection_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.zip\"\n",
    "zip_path = BASE_DIR / zip_filename\n",
    "\n",
    "shutil.make_archive(\n",
    "    str(zip_path).replace('.zip', ''),\n",
    "    'zip',\n",
    "    DOWNLOAD_DIR\n",
    ")\n",
    "\n",
    "zip_size_mb = zip_path.stat().st_size / 1024 / 1024\n",
    "print(f\"\\n‚úÖ Zip archive created: {zip_filename}\")\n",
    "print(f\"   Size: {zip_size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the complete package\n",
    "from google.colab import files\n",
    "\n",
    "print(\"üì• Starting download...\")\n",
    "print(\"\\nPackage contents:\")\n",
    "print(\"  üìÅ models/ - Trained model weights (best.pt, last.pt, ONNX)\")\n",
    "print(\"  üìÅ metrics/ - Training metrics CSV and configuration\")\n",
    "print(\"  üìÅ curves/ - All training curves and plots\")\n",
    "print(\"  üìÅ visualizations/ - Confusion matrices and label distributions\")\n",
    "print(\"  üìÅ batch_samples/ - Training and validation batch visualizations\")\n",
    "print(\"  üìÑ SUMMARY.txt - Results summary\")\n",
    "print()\n",
    "\n",
    "files.download(str(zip_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Summary\n",
    "\n",
    "Training complete! Here's what was accomplished:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print final summary\n",
    "print(\"=\" * 60)\n",
    "print(\"üéâ TRAINING COMPLETE!\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(f\"\\nüìä Dataset:\")\n",
    "print(f\"   Train: {train_count} images\")\n",
    "print(f\"   Val:   {val_count} images\")\n",
    "print(f\"   Test:  {test_count} images\")\n",
    "print(f\"   Total: {total_count} images\")\n",
    "\n",
    "print(f\"\\nü§ñ Model:\")\n",
    "print(f\"   Architecture: {MODEL_CONFIG['variant']}\")\n",
    "print(f\"   Image size: {DATASET_CONFIG['image_size']}\")\n",
    "print(f\"   Classes: {CLASS_NAMES}\")\n",
    "\n",
    "print(f\"\\nüìà Test Set Results:\")\n",
    "print(f\"   Precision:    {test_results.results_dict['metrics/precision(B)']:.4f}\")\n",
    "print(f\"   Recall:       {test_results.results_dict['metrics/recall(B)']:.4f}\")\n",
    "print(f\"   mAP@0.5:      {test_results.results_dict['metrics/mAP50(B)']:.4f}\")\n",
    "print(f\"   mAP@0.5:0.95: {test_results.results_dict['metrics/mAP50-95(B)']:.4f}\")\n",
    "\n",
    "print(f\"\\nüì¶ Download Package:\")\n",
    "print(f\"   {zip_filename} ({zip_size_mb:.2f} MB)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Next steps:\")\n",
    "print(\"1. Download the results package (click link above)\")\n",
    "print(\"2. Extract and review all metrics\")\n",
    "print(\"3. Deploy best.pt to Raspberry Pi 4B\")\n",
    "print(\"4. Run inference using inference.py\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìö Resources\n",
    "\n",
    "- **GitHub Repository:** [github.com/tanamujaya/lego_assembly_detection](https://github.com/tanamujaya/lego_assembly_detection)\n",
    "- **Dataset:** [Kaggle - LAD Dataset 5.0](https://www.kaggle.com/datasets/tanakamujaya/lad-dataset-5-0)\n",
    "- **YOLOv8 Documentation:** [docs.ultralytics.com](https://docs.ultralytics.com)\n",
    "\n",
    "---\n",
    "\n",
    "*Created as part of Bachelor's Thesis at HS Rhein-Waal University of Applied Sciences*"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
