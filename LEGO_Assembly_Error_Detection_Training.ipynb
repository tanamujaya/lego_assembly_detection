{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß± LEGO Assembly Error Detection - Training Notebook\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tanamujaya/lego_assembly_detection/blob/main/LEGO_Assembly_Error_Detection_Training.ipynb)\n",
    "\n",
    "This notebook trains a YOLO-based computer vision model to detect assembly errors in LEGO models.\n",
    "\n",
    "**Features:**\n",
    "- YOLOv8 object detection (nano version optimized for Raspberry Pi)\n",
    "- Automatic train/val/test split (70/15/15)\n",
    "- Evaluation metrics and visualization\n",
    "- Model export for Raspberry Pi deployment\n",
    "\n",
    "**Author:** Tanaka Mujaya  \n",
    "**Project:** Bachelor's Thesis - HS Rhein-Waal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Setup Environment\n",
    "\n",
    "First, let's check if we're running on GPU and install the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install ultralytics --quiet\n",
    "!pip install kaggle --quiet\n",
    "!pip install scikit-learn --quiet\n",
    "\n",
    "print(\"‚úÖ Packages installed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import zipfile\n",
    "import random\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image as PILImage\n",
    "from IPython.display import Image, display\n",
    "\n",
    "from ultralytics import YOLO\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Download Dataset from Kaggle\n",
    "\n",
    "The dataset is hosted on Kaggle. You'll need to upload your Kaggle API credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload your kaggle.json file\n",
    "# Go to https://www.kaggle.com/settings -> API -> Create New Token\n",
    "# This downloads a kaggle.json file\n",
    "\n",
    "from google.colab import files\n",
    "\n",
    "print(\"Please upload your kaggle.json file:\")\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Kaggle credentials\n",
    "# Handle both uppercase and lowercase filename\n",
    "!mkdir -p ~/.kaggle\n",
    "!mv -f kaggle.json ~/.kaggle/ 2>/dev/null || mv -f Kaggle.json ~/.kaggle/kaggle.json 2>/dev/null || echo \"File already moved\"\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "\n",
    "print(\"‚úÖ Kaggle credentials configured!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the dataset\n",
    "KAGGLE_DATASET = \"tanakamujaya/lego-assembly-detection-dataset\"\n",
    "\n",
    "!kaggle datasets download -d {KAGGLE_DATASET} -p /content/data --unzip\n",
    "\n",
    "print(\"‚úÖ Dataset downloaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the dataset structure\n",
    "print(\"=== Dataset Structure ===\")\n",
    "!find /content/data -type d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Configuration\n",
    "\n",
    "Set up training parameters and paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CONFIGURATION - Modify these settings as needed\n",
    "# ============================================================================\n",
    "\n",
    "# Paths\n",
    "BASE_DIR = Path(\"/content\")\n",
    "DATA_DIR = BASE_DIR / \"data\"\n",
    "MODELS_DIR = BASE_DIR / \"models\"\n",
    "RESULTS_DIR = BASE_DIR / \"results\"\n",
    "YOLO_DATASET_DIR = BASE_DIR / \"yolo_dataset\"\n",
    "\n",
    "# Create directories\n",
    "MODELS_DIR.mkdir(exist_ok=True)\n",
    "RESULTS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Dataset configuration\n",
    "DATASET_CONFIG = {\n",
    "    'train_split': 0.70,\n",
    "    'val_split': 0.15,\n",
    "    'test_split': 0.15,\n",
    "    'image_size': 416,  # Can use 320 for faster training, 640 for better accuracy\n",
    "    'random_seed': 42\n",
    "}\n",
    "\n",
    "# Model configuration\n",
    "MODEL_CONFIG = {\n",
    "    'variant': 'yolov8n',  # nano version (fastest, smallest)\n",
    "    'pretrained': True,\n",
    "    'num_classes': 2,  # correct_assembly, assembly_error\n",
    "}\n",
    "\n",
    "# Training configuration\n",
    "TRAINING_CONFIG = {\n",
    "    'epochs': 40,\n",
    "    'batch_size': 16,\n",
    "    'learning_rate': 0.001,\n",
    "    'patience': 20,  # Early stopping\n",
    "    'device': 0,  # GPU (use 'cpu' if no GPU)\n",
    "    'workers': 2,\n",
    "}\n",
    "\n",
    "# Class names\n",
    "CLASS_NAMES = ['correct_assembly', 'assembly_error']\n",
    "\n",
    "print(\"‚úÖ Configuration set!\")\n",
    "print(f\"   Model: {MODEL_CONFIG['variant']}\")\n",
    "print(f\"   Image size: {DATASET_CONFIG['image_size']}\")\n",
    "print(f\"   Epochs: {TRAINING_CONFIG['epochs']}\")\n",
    "print(f\"   Batch size: {TRAINING_CONFIG['batch_size']}\")\n",
    "print(f\"   Train/Val/Test split: {int(DATASET_CONFIG['train_split']*100)}/{int(DATASET_CONFIG['val_split']*100)}/{int(DATASET_CONFIG['test_split']*100)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Prepare Dataset\n",
    "\n",
    "Find the dataset, split into train/val/test, and create YOLO format structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_dataset(data_dir):\n",
    "    \"\"\"\n",
    "    Find the images and labels folders in the dataset.\n",
    "    Handles various folder structures and naming conventions.\n",
    "    \"\"\"\n",
    "    data_dir = Path(data_dir)\n",
    "    \n",
    "    print(\"üîç Searching for dataset...\")\n",
    "    \n",
    "    # Look for images folder (case-insensitive)\n",
    "    images_dir = None\n",
    "    labels_dir = None\n",
    "    \n",
    "    # Search for Images/images folder\n",
    "    for folder in data_dir.rglob('*'):\n",
    "        if folder.is_dir():\n",
    "            folder_name_lower = folder.name.lower()\n",
    "            if folder_name_lower == 'images':\n",
    "                images_dir = folder\n",
    "            elif folder_name_lower == 'labels':\n",
    "                labels_dir = folder\n",
    "    \n",
    "    if images_dir and labels_dir:\n",
    "        print(f\"   ‚úÖ Found dataset!\")\n",
    "        print(f\"   Images: {images_dir}\")\n",
    "        print(f\"   Labels: {labels_dir}\")\n",
    "        return images_dir, labels_dir\n",
    "    \n",
    "    raise FileNotFoundError(f\"Could not find Images/Labels folders in {data_dir}\")\n",
    "\n",
    "\n",
    "def get_image_label_pairs(images_dir, labels_dir):\n",
    "    \"\"\"\n",
    "    Get matching image and label file pairs.\n",
    "    \"\"\"\n",
    "    images_dir = Path(images_dir)\n",
    "    labels_dir = Path(labels_dir)\n",
    "    \n",
    "    image_extensions = {'.jpg', '.jpeg', '.png', '.bmp'}\n",
    "    pairs = []\n",
    "    \n",
    "    for img_path in images_dir.iterdir():\n",
    "        if img_path.suffix.lower() in image_extensions:\n",
    "            label_path = labels_dir / f\"{img_path.stem}.txt\"\n",
    "            if label_path.exists():\n",
    "                pairs.append((img_path, label_path))\n",
    "    \n",
    "    return pairs\n",
    "\n",
    "\n",
    "# Find the dataset\n",
    "images_dir, labels_dir = find_dataset(DATA_DIR)\n",
    "\n",
    "# Get all image-label pairs\n",
    "all_pairs = get_image_label_pairs(images_dir, labels_dir)\n",
    "print(f\"\\nüìä Found {len(all_pairs)} image-label pairs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_yolo_dataset(pairs, output_dir, train_ratio=0.7, val_ratio=0.15, test_ratio=0.15, seed=42):\n",
    "    \"\"\"\n",
    "    Split dataset and create YOLO format directory structure.\n",
    "    \"\"\"\n",
    "    output_dir = Path(output_dir)\n",
    "    \n",
    "    # Remove old dataset if exists\n",
    "    if output_dir.exists():\n",
    "        shutil.rmtree(output_dir)\n",
    "    \n",
    "    # Create directory structure\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        (output_dir / split / 'images').mkdir(parents=True, exist_ok=True)\n",
    "        (output_dir / split / 'labels').mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Split dataset\n",
    "    random.seed(seed)\n",
    "    shuffled_pairs = pairs.copy()\n",
    "    random.shuffle(shuffled_pairs)\n",
    "    \n",
    "    n_total = len(shuffled_pairs)\n",
    "    n_train = int(n_total * train_ratio)\n",
    "    n_val = int(n_total * val_ratio)\n",
    "    \n",
    "    train_pairs = shuffled_pairs[:n_train]\n",
    "    val_pairs = shuffled_pairs[n_train:n_train + n_val]\n",
    "    test_pairs = shuffled_pairs[n_train + n_val:]\n",
    "    \n",
    "    splits = {\n",
    "        'train': train_pairs,\n",
    "        'val': val_pairs,\n",
    "        'test': test_pairs\n",
    "    }\n",
    "    \n",
    "    # Copy files to respective directories\n",
    "    for split_name, split_pairs in splits.items():\n",
    "        print(f\"   Processing {split_name}: {len(split_pairs)} samples\")\n",
    "        for img_path, label_path in split_pairs:\n",
    "            shutil.copy(img_path, output_dir / split_name / 'images' / img_path.name)\n",
    "            shutil.copy(label_path, output_dir / split_name / 'labels' / label_path.name)\n",
    "    \n",
    "    # Create dataset.yaml\n",
    "    yaml_content = f\"\"\"# LEGO Assembly Error Detection Dataset\n",
    "# Auto-generated by training notebook\n",
    "\n",
    "path: {output_dir}\n",
    "train: train/images\n",
    "val: val/images\n",
    "test: test/images\n",
    "\n",
    "# Classes\n",
    "names:\n",
    "  0: correct_assembly\n",
    "  1: assembly_error\n",
    "\n",
    "# Number of classes\n",
    "nc: 2\n",
    "\"\"\"\n",
    "    \n",
    "    yaml_path = output_dir / 'dataset.yaml'\n",
    "    with open(yaml_path, 'w') as f:\n",
    "        f.write(yaml_content)\n",
    "    \n",
    "    return yaml_path, splits\n",
    "\n",
    "\n",
    "# Create YOLO dataset structure\n",
    "print(\"üìÅ Creating YOLO dataset structure...\")\n",
    "\n",
    "yaml_path, splits = create_yolo_dataset(\n",
    "    all_pairs,\n",
    "    YOLO_DATASET_DIR,\n",
    "    train_ratio=DATASET_CONFIG['train_split'],\n",
    "    val_ratio=DATASET_CONFIG['val_split'],\n",
    "    test_ratio=DATASET_CONFIG['test_split'],\n",
    "    seed=DATASET_CONFIG['random_seed']\n",
    ")\n",
    "\n",
    "train_count = len(splits['train'])\n",
    "val_count = len(splits['val'])\n",
    "test_count = len(splits['test'])\n",
    "total_count = train_count + val_count + test_count\n",
    "\n",
    "print(f\"\\n‚úÖ Dataset prepared!\")\n",
    "print(f\"   Train: {train_count} images ({train_count/total_count*100:.1f}%)\")\n",
    "print(f\"   Val:   {val_count} images ({val_count/total_count*100:.1f}%)\")\n",
    "print(f\"   Test:  {test_count} images ({test_count/total_count*100:.1f}%)\")\n",
    "print(f\"   Total: {total_count} images\")\n",
    "print(f\"\\n   YAML config: {yaml_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview some training images\n",
    "train_images_dir = YOLO_DATASET_DIR / 'train' / 'images'\n",
    "all_images = list(train_images_dir.iterdir())\n",
    "sample_images = random.sample(all_images, min(4, len(all_images)))\n",
    "\n",
    "fig, axes = plt.subplots(1, len(sample_images), figsize=(16, 4))\n",
    "if len(sample_images) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for ax, img_path in zip(axes, sample_images):\n",
    "    img = PILImage.open(img_path)\n",
    "    ax.imshow(img)\n",
    "    ax.set_title(img_path.name[:20] + '...')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.suptitle('Sample Training Images', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Train the Model\n",
    "\n",
    "Now let's train the YOLOv8 model on our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "print(f\"üöÄ Loading {MODEL_CONFIG['variant']} model...\")\n",
    "\n",
    "model = YOLO(f\"{MODEL_CONFIG['variant']}.pt\")\n",
    "\n",
    "print(\"‚úÖ Model loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "print(\"üèãÔ∏è Starting training...\")\n",
    "print(f\"   This may take a while depending on your GPU.\")\n",
    "print(f\"   Epochs: {TRAINING_CONFIG['epochs']}\")\n",
    "print(f\"   Batch size: {TRAINING_CONFIG['batch_size']}\")\n",
    "print()\n",
    "\n",
    "# Training arguments\n",
    "train_args = {\n",
    "    'data': str(yaml_path),\n",
    "    'epochs': TRAINING_CONFIG['epochs'],\n",
    "    'batch': TRAINING_CONFIG['batch_size'],\n",
    "    'imgsz': DATASET_CONFIG['image_size'],\n",
    "    'device': TRAINING_CONFIG['device'],\n",
    "    'workers': TRAINING_CONFIG['workers'],\n",
    "    'patience': TRAINING_CONFIG['patience'],\n",
    "    'save': True,\n",
    "    'project': str(RESULTS_DIR),\n",
    "    'name': 'lego_detection',\n",
    "    'exist_ok': True,\n",
    "    'pretrained': MODEL_CONFIG['pretrained'],\n",
    "    'optimizer': 'Adam',\n",
    "    'lr0': TRAINING_CONFIG['learning_rate'],\n",
    "    'verbose': True,\n",
    "    'plots': True,\n",
    "    # Augmentation\n",
    "    'hsv_h': 0.015,\n",
    "    'hsv_s': 0.7,\n",
    "    'hsv_v': 0.4,\n",
    "    'degrees': 10,\n",
    "    'translate': 0.1,\n",
    "    'scale': 0.5,\n",
    "    'fliplr': 0.5,\n",
    "    'mosaic': 1.0,\n",
    "    'mixup': 0.1,\n",
    "}\n",
    "\n",
    "# Start training\n",
    "results = model.train(**train_args)\n",
    "\n",
    "print(\"\\n‚úÖ Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Evaluate Results\n",
    "\n",
    "Let's look at the training metrics and evaluate on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display training results\n",
    "results_dir = RESULTS_DIR / 'lego_detection'\n",
    "\n",
    "# Show results plot\n",
    "results_img = results_dir / 'results.png'\n",
    "if results_img.exists():\n",
    "    display(Image(filename=str(results_img), width=800))\n",
    "else:\n",
    "    print(\"Results plot not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show confusion matrix\n",
    "confusion_matrix_img = results_dir / 'confusion_matrix.png'\n",
    "if confusion_matrix_img.exists():\n",
    "    display(Image(filename=str(confusion_matrix_img), width=500))\n",
    "else:\n",
    "    print(\"Confusion matrix not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show PR curve\n",
    "pr_curve_img = results_dir / 'PR_curve.png'\n",
    "if pr_curve_img.exists():\n",
    "    display(Image(filename=str(pr_curve_img), width=500))\n",
    "else:\n",
    "    print(\"PR curve not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "print(\"üìä Evaluating on test set...\")\n",
    "\n",
    "# Load best model\n",
    "best_model_path = results_dir / 'weights' / 'best.pt'\n",
    "best_model = YOLO(str(best_model_path))\n",
    "\n",
    "# Run evaluation on test set\n",
    "test_results = best_model.val(\n",
    "    data=str(yaml_path),\n",
    "    split='test',\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"üìà TEST SET RESULTS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Precision:    {test_results.results_dict['metrics/precision(B)']:.4f}\")\n",
    "print(f\"Recall:       {test_results.results_dict['metrics/recall(B)']:.4f}\")\n",
    "print(f\"mAP@0.5:      {test_results.results_dict['metrics/mAP50(B)']:.4f}\")\n",
    "print(f\"mAP@0.5:0.95: {test_results.results_dict['metrics/mAP50-95(B)']:.4f}\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Test Inference\n",
    "\n",
    "Let's run inference on some test images to see the model in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference on random test images\n",
    "test_images_dir = YOLO_DATASET_DIR / 'test' / 'images'\n",
    "test_images = list(test_images_dir.iterdir())\n",
    "sample_test_images = random.sample(test_images, min(4, len(test_images)))\n",
    "\n",
    "print(\"üîç Running inference on sample test images...\\n\")\n",
    "\n",
    "# Run prediction\n",
    "predictions = best_model.predict(\n",
    "    source=sample_test_images,\n",
    "    save=True,\n",
    "    project=str(RESULTS_DIR),\n",
    "    name='test_predictions',\n",
    "    exist_ok=True,\n",
    "    conf=0.5\n",
    ")\n",
    "\n",
    "# Display predictions\n",
    "pred_dir = RESULTS_DIR / 'test_predictions'\n",
    "pred_images = [f for f in pred_dir.iterdir() if f.suffix.lower() in {'.jpg', '.jpeg', '.png'}]\n",
    "\n",
    "if pred_images:\n",
    "    fig, axes = plt.subplots(1, len(pred_images), figsize=(16, 4))\n",
    "    if len(pred_images) == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for ax, img_path in zip(axes, pred_images):\n",
    "        img = PILImage.open(img_path)\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(img_path.name[:25])\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.suptitle('Model Predictions on Test Images', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No prediction images found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Save and Download Model\n",
    "\n",
    "Save the trained model and download it for deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy best model to models directory\n",
    "final_model_path = MODELS_DIR / 'lego_detector_best.pt'\n",
    "shutil.copy(best_model_path, final_model_path)\n",
    "\n",
    "print(f\"‚úÖ Best model saved to: {final_model_path}\")\n",
    "print(f\"   Model size: {final_model_path.stat().st_size / 1024 / 1024:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to ONNX format (optional - for optimized inference)\n",
    "print(\"üì¶ Exporting to ONNX format...\")\n",
    "\n",
    "onnx_path = best_model.export(\n",
    "    format='onnx',\n",
    "    imgsz=DATASET_CONFIG['image_size'],\n",
    "    simplify=True\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ ONNX model saved to: {onnx_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the model\n",
    "from google.colab import files\n",
    "\n",
    "print(\"üì• Preparing model for download...\")\n",
    "\n",
    "# Create a zip with the model and results\n",
    "zip_path = '/content/lego_detector_model.zip'\n",
    "with zipfile.ZipFile(zip_path, 'w') as zipf:\n",
    "    zipf.write(final_model_path, 'lego_detector_best.pt')\n",
    "    if Path(onnx_path).exists():\n",
    "        zipf.write(onnx_path, Path(onnx_path).name)\n",
    "\n",
    "print(f\"\\n‚úÖ Model package ready!\")\n",
    "print(f\"   Click below to download:\")\n",
    "\n",
    "files.download(zip_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Summary\n",
    "\n",
    "Training complete! Here's what was accomplished:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print summary\n",
    "print(\"=\"*60)\n",
    "print(\"üéâ TRAINING SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nüìä Dataset:\")\n",
    "print(f\"   Train: {train_count} images\")\n",
    "print(f\"   Val:   {val_count} images\")\n",
    "print(f\"   Test:  {test_count} images\")\n",
    "print(f\"   Total: {total_count} images\")\n",
    "\n",
    "print(f\"\\nü§ñ Model:\")\n",
    "print(f\"   Architecture: {MODEL_CONFIG['variant']}\")\n",
    "print(f\"   Image size: {DATASET_CONFIG['image_size']}\")\n",
    "print(f\"   Classes: {CLASS_NAMES}\")\n",
    "\n",
    "print(f\"\\nüìà Test Results:\")\n",
    "print(f\"   Precision: {test_results.results_dict['metrics/precision(B)']:.4f}\")\n",
    "print(f\"   Recall: {test_results.results_dict['metrics/recall(B)']:.4f}\")\n",
    "print(f\"   mAP@0.5: {test_results.results_dict['metrics/mAP50(B)']:.4f}\")\n",
    "\n",
    "print(f\"\\nüìÅ Outputs:\")\n",
    "print(f\"   Best model: {final_model_path}\")\n",
    "print(f\"   Results: {results_dir}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Next steps:\")\n",
    "print(\"1. Download the model zip file\")\n",
    "print(\"2. Deploy to Raspberry Pi 4B\")\n",
    "print(\"3. Run inference using inference.py\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìö Resources\n",
    "\n",
    "- **GitHub Repository:** [github.com/tanamujaya/lego_assembly_detection](https://github.com/tanamujaya/lego_assembly_detection)\n",
    "- **Dataset:** [Kaggle - LEGO Assembly Detection Dataset](https://www.kaggle.com/datasets/tanakamujaya/lego-assembly-detection-dataset)\n",
    "- **YOLOv8 Documentation:** [docs.ultralytics.com](https://docs.ultralytics.com)\n",
    "\n",
    "---\n",
    "\n",
    "*Created as part of Bachelor's Thesis at HS Rhein-Waal*"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
