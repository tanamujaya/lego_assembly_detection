{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß± LEGO Assembly Error Detection - Training Notebook\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/tanamujaya/lego_assembly_detection/blob/main/LEGO_Assembly_Error_Detection_Training.ipynb)\n",
    "\n",
    "This notebook trains a YOLO-based computer vision model to detect assembly errors in LEGO models.\n",
    "\n",
    "**Features:**\n",
    "- YOLOv8 object detection (nano version optimized for Raspberry Pi)\n",
    "- K-fold cross-validation support\n",
    "- Few-shot fine-tuning capabilities\n",
    "- Automatic evaluation and metrics visualization\n",
    "\n",
    "**Author:** Tanaka Mujaya  \n",
    "**Project:** Bachelor's Thesis - HS Rhein-Waal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Setup Environment\n",
    "\n",
    "First, let's check if we're running on GPU and install the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install ultralytics --quiet\n",
    "!pip install kaggle --quiet\n",
    "!pip install scikit-learn --quiet\n",
    "\n",
    "print(\"‚úÖ Packages installed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image, display\n",
    "\n",
    "from ultralytics import YOLO\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Download Dataset from Kaggle\n",
    "\n",
    "The dataset is hosted on Kaggle. You'll need to upload your Kaggle API credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload your kaggle.json file\n",
    "# Go to https://www.kaggle.com/settings -> API -> Create New Token\n",
    "# This downloads a kaggle.json file\n",
    "\n",
    "from google.colab import files\n",
    "\n",
    "print(\"Please upload your kaggle.json file:\")\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Kaggle credentials\n",
    "# Handle both uppercase and lowercase filename\n",
    "!mkdir -p ~/.kaggle\n",
    "!mv -f kaggle.json ~/.kaggle/ 2>/dev/null || mv -f Kaggle.json ~/.kaggle/kaggle.json 2>/dev/null || echo \"File already moved\"\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n",
    "\n",
    "print(\"‚úÖ Kaggle credentials configured!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the dataset\n",
    "KAGGLE_DATASET = \"tanakamujaya/lego-assembly-detection-dataset\"\n",
    "\n",
    "!kaggle datasets download -d {KAGGLE_DATASET} -p /content/data --unzip\n",
    "\n",
    "print(\"‚úÖ Dataset downloaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the dataset structure\n",
    "!echo \"=== Dataset Structure ===\"\n",
    "!find /content/data -type d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Configuration\n",
    "\n",
    "Set up training parameters and paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CONFIGURATION - Modify these settings as needed\n",
    "# ============================================================================\n",
    "\n",
    "# Paths\n",
    "BASE_DIR = Path(\"/content\")\n",
    "DATA_DIR = BASE_DIR / \"data\"\n",
    "MODELS_DIR = BASE_DIR / \"models\"\n",
    "RESULTS_DIR = BASE_DIR / \"results\"\n",
    "\n",
    "# Create directories\n",
    "MODELS_DIR.mkdir(exist_ok=True)\n",
    "RESULTS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# Dataset configuration\n",
    "DATASET_CONFIG = {\n",
    "    'image_size': 416,  # Can use 320 for faster training\n",
    "    'random_seed': 42\n",
    "}\n",
    "\n",
    "# Model configuration\n",
    "MODEL_CONFIG = {\n",
    "    'variant': 'yolov8n',  # nano version (fastest, smallest)\n",
    "    'pretrained': True,\n",
    "    'num_classes': 2,  # correct_assembly, assembly_error\n",
    "}\n",
    "\n",
    "# Training configuration\n",
    "TRAINING_CONFIG = {\n",
    "    'epochs': 40,\n",
    "    'batch_size': 16,\n",
    "    'learning_rate': 0.001,\n",
    "    'patience': 20,  # Early stopping\n",
    "    'device': 0,  # GPU (use 'cpu' if no GPU)\n",
    "    'workers': 2,\n",
    "}\n",
    "\n",
    "# Class names\n",
    "CLASS_NAMES = ['correct_assembly', 'assembly_error']\n",
    "\n",
    "print(\"‚úÖ Configuration set!\")\n",
    "print(f\"   Model: {MODEL_CONFIG['variant']}\")\n",
    "print(f\"   Image size: {DATASET_CONFIG['image_size']}\")\n",
    "print(f\"   Epochs: {TRAINING_CONFIG['epochs']}\")\n",
    "print(f\"   Batch size: {TRAINING_CONFIG['batch_size']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Prepare Dataset\n",
    "\n",
    "Locate the `combined_dataset` folder and create the YOLO configuration file.\n",
    "\n",
    "**Note:** The dataset is already pre-split into train/val folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_combined_dataset(data_dir):\n",
    "    \"\"\"\n",
    "    Find the combined_dataset folder which contains the full training data.\n",
    "    Handles pre-split datasets (with train/val subfolders).\n",
    "    \"\"\"\n",
    "    data_dir = Path(data_dir)\n",
    "    \n",
    "    print(\"üîç Searching for combined_dataset...\")\n",
    "    \n",
    "    # Search for combined_dataset anywhere in the directory tree\n",
    "    for combined_dir in data_dir.rglob('combined_dataset'):\n",
    "        # Check if it's a pre-split dataset (has train/val subfolders)\n",
    "        train_dir = combined_dir / 'train'\n",
    "        val_dir = combined_dir / 'val'\n",
    "        \n",
    "        if train_dir.exists() and val_dir.exists():\n",
    "            print(f\"   ‚úÖ Found pre-split combined_dataset!\")\n",
    "            print(f\"   Location: {combined_dir}\")\n",
    "            return combined_dir, 'pre-split'\n",
    "        \n",
    "        # Check if it has direct images/labels folders\n",
    "        images_dir = combined_dir / 'images'\n",
    "        labels_dir = combined_dir / 'labels'\n",
    "        \n",
    "        if images_dir.exists() and labels_dir.exists():\n",
    "            print(f\"   ‚úÖ Found combined_dataset!\")\n",
    "            print(f\"   Location: {combined_dir}\")\n",
    "            return combined_dir, 'flat'\n",
    "    \n",
    "    # Fallback: look for any dataset with train folder\n",
    "    print(\"   ‚ö†Ô∏è combined_dataset not found, searching for alternatives...\")\n",
    "    \n",
    "    for subdir in data_dir.rglob('train'):\n",
    "        if (subdir / 'images').exists() and (subdir / 'labels').exists():\n",
    "            parent = subdir.parent\n",
    "            print(f\"   Using: {parent.name}\")\n",
    "            return parent, 'pre-split'\n",
    "    \n",
    "    raise FileNotFoundError(f\"Could not find a valid dataset in {data_dir}\")\n",
    "\n",
    "\n",
    "def count_images(directory):\n",
    "    \"\"\"Count images in a directory.\"\"\"\n",
    "    directory = Path(directory)\n",
    "    if not directory.exists():\n",
    "        return 0\n",
    "    image_extensions = {'.jpg', '.jpeg', '.png', '.bmp'}\n",
    "    return sum(1 for f in directory.iterdir() if f.suffix.lower() in image_extensions)\n",
    "\n",
    "\n",
    "# Find the dataset\n",
    "dataset_dir, dataset_type = find_combined_dataset(DATA_DIR)\n",
    "\n",
    "# Count samples\n",
    "if dataset_type == 'pre-split':\n",
    "    train_count = count_images(dataset_dir / 'train' / 'images')\n",
    "    val_count = count_images(dataset_dir / 'val' / 'images')\n",
    "    test_count = count_images(dataset_dir / 'test' / 'images') if (dataset_dir / 'test').exists() else 0\n",
    "    total_count = train_count + val_count + test_count\n",
    "    \n",
    "    print(f\"\\nüìä Dataset Statistics:\")\n",
    "    print(f\"   Train: {train_count} images\")\n",
    "    print(f\"   Val: {val_count} images\")\n",
    "    if test_count > 0:\n",
    "        print(f\"   Test: {test_count} images\")\n",
    "    print(f\"   Total: {total_count} images\")\n",
    "else:\n",
    "    total_count = count_images(dataset_dir / 'images')\n",
    "    print(f\"\\nüìä Total images: {total_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_yaml(dataset_dir, output_path, dataset_type='pre-split'):\n",
    "    \"\"\"\n",
    "    Create a YOLO dataset.yaml configuration file.\n",
    "    \"\"\"\n",
    "    dataset_dir = Path(dataset_dir)\n",
    "    output_path = Path(output_path)\n",
    "    \n",
    "    # Determine paths based on dataset type\n",
    "    if dataset_type == 'pre-split':\n",
    "        train_path = 'train/images'\n",
    "        val_path = 'val/images'\n",
    "        test_path = 'test/images' if (dataset_dir / 'test').exists() else 'val/images'\n",
    "    else:\n",
    "        train_path = 'images'\n",
    "        val_path = 'images'\n",
    "        test_path = 'images'\n",
    "    \n",
    "    yaml_content = f\"\"\"# LEGO Assembly Error Detection Dataset\n",
    "# Auto-generated by training notebook\n",
    "\n",
    "path: {dataset_dir}\n",
    "train: {train_path}\n",
    "val: {val_path}\n",
    "test: {test_path}\n",
    "\n",
    "# Classes\n",
    "names:\n",
    "  0: correct_assembly\n",
    "  1: assembly_error\n",
    "\n",
    "# Number of classes\n",
    "nc: 2\n",
    "\"\"\"\n",
    "    \n",
    "    with open(output_path, 'w') as f:\n",
    "        f.write(yaml_content)\n",
    "    \n",
    "    print(f\"‚úÖ Created dataset.yaml at: {output_path}\")\n",
    "    return output_path\n",
    "\n",
    "\n",
    "# Create the YAML configuration\n",
    "yaml_path = BASE_DIR / 'dataset.yaml'\n",
    "yaml_path = create_dataset_yaml(dataset_dir, yaml_path, dataset_type)\n",
    "\n",
    "# Display the YAML content\n",
    "print(\"\\nüìÑ Dataset configuration:\")\n",
    "print(\"-\" * 40)\n",
    "!cat {yaml_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview some training images\n",
    "import random\n",
    "from PIL import Image as PILImage\n",
    "\n",
    "if dataset_type == 'pre-split':\n",
    "    train_images_dir = dataset_dir / 'train' / 'images'\n",
    "else:\n",
    "    train_images_dir = dataset_dir / 'images'\n",
    "\n",
    "all_images = list(train_images_dir.iterdir())\n",
    "sample_images = random.sample(all_images, min(4, len(all_images)))\n",
    "\n",
    "fig, axes = plt.subplots(1, len(sample_images), figsize=(16, 4))\n",
    "if len(sample_images) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for ax, img_path in zip(axes, sample_images):\n",
    "    img = PILImage.open(img_path)\n",
    "    ax.imshow(img)\n",
    "    ax.set_title(img_path.name[:20] + '...')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.suptitle('Sample Training Images', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Train the Model\n",
    "\n",
    "Now let's train the YOLOv8 model on our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "print(f\"üöÄ Loading {MODEL_CONFIG['variant']} model...\")\n",
    "\n",
    "model = YOLO(f\"{MODEL_CONFIG['variant']}.pt\")\n",
    "\n",
    "print(\"‚úÖ Model loaded!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "print(\"üèãÔ∏è Starting training...\")\n",
    "print(f\"   This may take a while depending on your GPU.\")\n",
    "print(f\"   Epochs: {TRAINING_CONFIG['epochs']}\")\n",
    "print(f\"   Batch size: {TRAINING_CONFIG['batch_size']}\")\n",
    "print()\n",
    "\n",
    "# Training arguments\n",
    "train_args = {\n",
    "    'data': str(yaml_path),\n",
    "    'epochs': TRAINING_CONFIG['epochs'],\n",
    "    'batch': TRAINING_CONFIG['batch_size'],\n",
    "    'imgsz': DATASET_CONFIG['image_size'],\n",
    "    'device': TRAINING_CONFIG['device'],\n",
    "    'workers': TRAINING_CONFIG['workers'],\n",
    "    'patience': TRAINING_CONFIG['patience'],\n",
    "    'save': True,\n",
    "    'project': str(RESULTS_DIR),\n",
    "    'name': 'lego_detection',\n",
    "    'exist_ok': True,\n",
    "    'pretrained': MODEL_CONFIG['pretrained'],\n",
    "    'optimizer': 'Adam',\n",
    "    'lr0': TRAINING_CONFIG['learning_rate'],\n",
    "    'verbose': True,\n",
    "    'plots': True,\n",
    "    # Augmentation\n",
    "    'hsv_h': 0.015,\n",
    "    'hsv_s': 0.7,\n",
    "    'hsv_v': 0.4,\n",
    "    'degrees': 10,\n",
    "    'translate': 0.1,\n",
    "    'scale': 0.5,\n",
    "    'fliplr': 0.5,\n",
    "    'mosaic': 1.0,\n",
    "    'mixup': 0.1,\n",
    "}\n",
    "\n",
    "# Start training\n",
    "results = model.train(**train_args)\n",
    "\n",
    "print(\"\\n‚úÖ Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Evaluate Results\n",
    "\n",
    "Let's look at the training metrics and evaluate on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display training results\n",
    "results_dir = RESULTS_DIR / 'lego_detection'\n",
    "\n",
    "# Show results plot\n",
    "results_img = results_dir / 'results.png'\n",
    "if results_img.exists():\n",
    "    display(Image(filename=str(results_img), width=800))\n",
    "else:\n",
    "    print(\"Results plot not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show confusion matrix\n",
    "confusion_matrix_img = results_dir / 'confusion_matrix.png'\n",
    "if confusion_matrix_img.exists():\n",
    "    display(Image(filename=str(confusion_matrix_img), width=500))\n",
    "else:\n",
    "    print(\"Confusion matrix not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show PR curve\n",
    "pr_curve_img = results_dir / 'PR_curve.png'\n",
    "if pr_curve_img.exists():\n",
    "    display(Image(filename=str(pr_curve_img), width=500))\n",
    "else:\n",
    "    print(\"PR curve not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on validation set\n",
    "print(\"üìä Evaluating on validation set...\")\n",
    "\n",
    "# Load best model\n",
    "best_model_path = results_dir / 'weights' / 'best.pt'\n",
    "best_model = YOLO(str(best_model_path))\n",
    "\n",
    "# Run validation\n",
    "val_results = best_model.val(\n",
    "    data=str(yaml_path),\n",
    "    split='val',\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"üìà VALIDATION RESULTS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Precision:    {val_results.results_dict['metrics/precision(B)']:.4f}\")\n",
    "print(f\"Recall:       {val_results.results_dict['metrics/recall(B)']:.4f}\")\n",
    "print(f\"mAP@0.5:      {val_results.results_dict['metrics/mAP50(B)']:.4f}\")\n",
    "print(f\"mAP@0.5:0.95: {val_results.results_dict['metrics/mAP50-95(B)']:.4f}\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Test Inference\n",
    "\n",
    "Let's run inference on some validation images to see the model in action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference on random validation images\n",
    "if dataset_type == 'pre-split':\n",
    "    val_images_dir = dataset_dir / 'val' / 'images'\n",
    "else:\n",
    "    val_images_dir = dataset_dir / 'images'\n",
    "\n",
    "val_images = list(val_images_dir.iterdir())\n",
    "sample_val_images = random.sample(val_images, min(4, len(val_images)))\n",
    "\n",
    "print(\"üîç Running inference on sample images...\\n\")\n",
    "\n",
    "# Run prediction\n",
    "predictions = best_model.predict(\n",
    "    source=sample_val_images,\n",
    "    save=True,\n",
    "    project=str(RESULTS_DIR),\n",
    "    name='test_predictions',\n",
    "    exist_ok=True,\n",
    "    conf=0.5\n",
    ")\n",
    "\n",
    "# Display predictions\n",
    "pred_dir = RESULTS_DIR / 'test_predictions'\n",
    "pred_images = [f for f in pred_dir.iterdir() if f.suffix.lower() in {'.jpg', '.jpeg', '.png'}]\n",
    "\n",
    "if pred_images:\n",
    "    fig, axes = plt.subplots(1, len(pred_images), figsize=(16, 4))\n",
    "    if len(pred_images) == 1:\n",
    "        axes = [axes]\n",
    "\n",
    "    for ax, img_path in zip(axes, pred_images):\n",
    "        img = PILImage.open(img_path)\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(img_path.name[:25])\n",
    "        ax.axis('off')\n",
    "\n",
    "    plt.suptitle('Model Predictions', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No prediction images found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 8. Save and Download Model\n",
    "\n",
    "Save the trained model and download it for deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy best model to models directory\n",
    "final_model_path = MODELS_DIR / 'lego_detector_best.pt'\n",
    "shutil.copy(best_model_path, final_model_path)\n",
    "\n",
    "print(f\"‚úÖ Best model saved to: {final_model_path}\")\n",
    "print(f\"   Model size: {final_model_path.stat().st_size / 1024 / 1024:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to ONNX format (optional - for optimized inference)\n",
    "print(\"üì¶ Exporting to ONNX format...\")\n",
    "\n",
    "onnx_path = best_model.export(\n",
    "    format='onnx',\n",
    "    imgsz=DATASET_CONFIG['image_size'],\n",
    "    simplify=True\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ ONNX model saved to: {onnx_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the model\n",
    "from google.colab import files\n",
    "\n",
    "print(\"üì• Preparing model for download...\")\n",
    "\n",
    "# Create a zip with the model and results\n",
    "zip_path = '/content/lego_detector_model.zip'\n",
    "with zipfile.ZipFile(zip_path, 'w') as zipf:\n",
    "    zipf.write(final_model_path, 'lego_detector_best.pt')\n",
    "    if Path(onnx_path).exists():\n",
    "        zipf.write(onnx_path, Path(onnx_path).name)\n",
    "\n",
    "print(f\"\\n‚úÖ Model package ready!\")\n",
    "print(f\"   Click below to download:\")\n",
    "\n",
    "files.download(zip_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 9. Summary\n",
    "\n",
    "Training complete! Here's what was accomplished:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print summary\n",
    "print(\"=\"*60)\n",
    "print(\"üéâ TRAINING SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nüìä Dataset:\")\n",
    "if dataset_type == 'pre-split':\n",
    "    print(f\"   Train: {train_count} images\")\n",
    "    print(f\"   Val: {val_count} images\")\n",
    "    if test_count > 0:\n",
    "        print(f\"   Test: {test_count} images\")\n",
    "    print(f\"   Total: {total_count} images\")\n",
    "else:\n",
    "    print(f\"   Total: {total_count} images\")\n",
    "\n",
    "print(f\"\\nü§ñ Model:\")\n",
    "print(f\"   Architecture: {MODEL_CONFIG['variant']}\")\n",
    "print(f\"   Image size: {DATASET_CONFIG['image_size']}\")\n",
    "print(f\"   Classes: {CLASS_NAMES}\")\n",
    "\n",
    "print(f\"\\nüìà Validation Results:\")\n",
    "print(f\"   Precision: {val_results.results_dict['metrics/precision(B)']:.4f}\")\n",
    "print(f\"   Recall: {val_results.results_dict['metrics/recall(B)']:.4f}\")\n",
    "print(f\"   mAP@0.5: {val_results.results_dict['metrics/mAP50(B)']:.4f}\")\n",
    "\n",
    "print(f\"\\nüìÅ Outputs:\")\n",
    "print(f\"   Best model: {final_model_path}\")\n",
    "print(f\"   Results: {results_dir}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Next steps:\")\n",
    "print(\"1. Download the model zip file\")\n",
    "print(\"2. Deploy to Raspberry Pi 4B\")\n",
    "print(\"3. Run inference using inference.py\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìö Resources\n",
    "\n",
    "- **GitHub Repository:** [github.com/tanamujaya/lego_assembly_detection](https://github.com/tanamujaya/lego_assembly_detection)\n",
    "- **Dataset:** [Kaggle - LEGO Assembly Detection Dataset](https://www.kaggle.com/datasets/tanakamujaya/lego-assembly-detection-dataset)\n",
    "- **YOLOv8 Documentation:** [docs.ultralytics.com](https://docs.ultralytics.com)\n",
    "\n",
    "---\n",
    "\n",
    "*Created as part of Bachelor's Thesis at HS Rhein-Waal*"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
